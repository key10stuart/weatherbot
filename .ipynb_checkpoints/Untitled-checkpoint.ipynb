{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb3d66e-5141-4ea9-860c-660eb041b0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "{\n",
      "  \"npz\": \"data/processed/sav_0927_v3.npz\",\n",
      "  \"horizon\": 24,\n",
      "  \"lookback\": 168,\n",
      "  \"batch_size\": 128,\n",
      "  \"epochs\": 80,\n",
      "  \"lr\": 0.0003,\n",
      "  \"channels\": 64,\n",
      "  \"kernel\": 5,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dilations\": \"1,2,4,8,16,32\",\n",
      "  \"seed\": 42,\n",
      "  \"save\": \"best_model.pt\",\n",
      "  \"num_workers\": 0,\n",
      "  \"target_feat_idx\": -1,\n",
      "  \"use_torch_compile\": true\n",
      "}\n",
      "\n",
      "Using device: mps\n",
      "Autotuned Configuration:\n",
      "{\n",
      "  \"npz\": \"data/processed/sav_0927_v3.npz\",\n",
      "  \"horizon\": 24,\n",
      "  \"lookback\": 168,\n",
      "  \"batch_size\": 128,\n",
      "  \"epochs\": 80,\n",
      "  \"lr\": 0.0003,\n",
      "  \"channels\": 64,\n",
      "  \"kernel\": 5,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dilations\": \"1,2,4,8,16,32\",\n",
      "  \"seed\": 42,\n",
      "  \"save\": \"best_model.pt\",\n",
      "  \"num_workers\": 4,\n",
      "  \"target_feat_idx\": -1,\n",
      "  \"use_torch_compile\": true\n",
      "}\n",
      "Dataset sizes — train: 60718, val: 13011, test: 13012\n",
      "Features (F): 5, Lookback (L): 168, Horizon (H): 24\n",
      "\n",
      "⚠️  Lookback (168) < receptive field (505). Consider increasing lookback or reducing k/dilations.\n",
      "torch.compile enabled.\n",
      "Model params: 250,136\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/miniconda3/envs/ai/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/miniconda3/envs/ai/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'TSWindowDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/miniconda3/envs/ai/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/miniconda3/envs/ai/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'TSWindowDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/miniconda3/envs/ai/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/miniconda3/envs/ai/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'TSWindowDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/miniconda3/envs/ai/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/miniconda3/envs/ai/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'TSWindowDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 9017) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/ai/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ai/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ai/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ai/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ai/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ai/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ai/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 9017) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 427\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh+\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: RMSE_model=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mph_m[h]\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  |  RMSE_persist=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mph_b[h]\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  |  Skill=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mph_skill[h]\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 427\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 374\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# === Train Model ===\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 374\u001b[0m best_val_rmse \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\n\u001b[1;32m    377\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining finished. Best validation RMSE (masked): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_val_rmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# === Save Model & Normalization Stats ===\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 247\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, loaders, device, epochs, max_lr, clip, patience)\u001b[0m\n\u001b[1;32m    245\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    246\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xb, yb, x_mask_b, y_mask_b \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    248\u001b[0m     xb, yb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(device), yb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    249\u001b[0m     y_mask_b \u001b[38;5;241m=\u001b[39m y_mask_b\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ai/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ai/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ai/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ai/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 9017) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "import math, os, sys, time, json, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Tuple\n",
    "\n",
    "#___________________________________________________________________________________________________\n",
    "##\n",
    "## Reproducibility & Global Setup\n",
    "##___________________________________________________________________________________________________\n",
    "\n",
    "def set_seed(s: int = 42):\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    torch.manual_seed(s)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(s)\n",
    "\n",
    "#___________________________________________________________________________________________________\n",
    "##\n",
    "## Data Utilities\n",
    "##___________________________________________________________________________________________________\n",
    "\n",
    "def _squeeze_last_if_singleton(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"If target is (N, H, 1) or (N, 1), drop the last dim.\"\"\"\n",
    "    return a[..., 0] if (a.ndim >= 2 and a.shape[-1] == 1) else a\n",
    "\n",
    "def load_npz(path: str):\n",
    "    \"\"\"Load NPZ with keys: X_train, y_train, X_val, y_val, X_test, y_test.\"\"\"\n",
    "    npz = np.load(path)\n",
    "    X_train = npz[\"X_train\"]\n",
    "    y_train = _squeeze_last_if_singleton(npz[\"y_train\"])\n",
    "    X_val   = npz[\"X_val\"]\n",
    "    y_val   = _squeeze_last_if_singleton(npz[\"y_val\"])\n",
    "    X_test  = npz[\"X_test\"]\n",
    "    y_test  = _squeeze_last_if_singleton(npz[\"y_test\"])\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "#___________________________________________________________________________________________________\n",
    "##\n",
    "## Normalization & Dataset (MASKING)\n",
    "##___________________________________________________________________________________________________\n",
    "\n",
    "def zscore_fit(X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Compute per-feature μ/σ from TRAIN windows only. X: [N, L, F]. NaN-aware.\"\"\"\n",
    "    mu = np.nanmean(X.reshape(-1, X.shape[-1]), axis=0)\n",
    "    sd = np.nanstd(X.reshape(-1, X.shape[-1]), axis=0)\n",
    "    sd = np.where(sd < 1e-8, 1.0, sd)\n",
    "    return mu.astype(np.float32), sd.astype(np.float32)\n",
    "\n",
    "def zscore_apply(X: np.ndarray, mu: np.ndarray, sd: np.ndarray) -> np.ndarray:\n",
    "    return (X - mu) / sd\n",
    "\n",
    "class TSWindowDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that builds masks for NaNs and zero-imputes AFTER capturing masks.\n",
    "    x_mask: [N, L] where 1.0 = valid timestep (all feats present), 0.0 = masked\n",
    "    y_mask: [N, H] where 1.0 = valid target, 0.0 = masked\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        x_nan_mask = np.isnan(X).any(axis=2)  # [N, L]\n",
    "        y_nan_mask = np.isnan(y)              # [N, H]\n",
    "        self.x_mask = torch.as_tensor(~x_nan_mask, dtype=torch.float32)\n",
    "        self.y_mask = torch.as_tensor(~y_nan_mask, dtype=torch.float32)\n",
    "\n",
    "        X = X.copy()\n",
    "        y = y.copy()\n",
    "        X[np.isnan(X)] = 0.0\n",
    "        y[np.isnan(y)] = 0.0\n",
    "\n",
    "        self.X = torch.as_tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.as_tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i], self.x_mask[i], self.y_mask[i]\n",
    "\n",
    "#___________________________________________________________________________________________________\n",
    "##\n",
    "## Device Selection & Autotuning Heuristics\n",
    "##___________________________________________________________________________________________________\n",
    "\n",
    "def pick_device():\n",
    "    \"\"\"Prefer MPS (Apple Silicon), else CPU.\"\"\"\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "def autotune_hparams(CFG, device):\n",
    "    tuned = dict(CFG)\n",
    "    if device.type == \"mps\":\n",
    "        tuned[\"num_workers\"] = max(tuned.get(\"num_workers\", 0), 4)\n",
    "        return tuned\n",
    "    tuned[\"batch_size\"]  = min(CFG.get(\"batch_size\", 128), 64)\n",
    "    tuned[\"channels\"]    = min(CFG.get(\"channels\", 64), 48)\n",
    "    tuned[\"num_workers\"] = max(CFG.get(\"num_workers\", 0), 2)\n",
    "    tuned[\"lr\"]          = min(CFG.get(\"lr\", 3e-3), 2e-3)\n",
    "    return tuned\n",
    "\n",
    "#___________________________________________________________________________________________________\n",
    "##\n",
    "## Model: Dilated Causal CNN\n",
    "##___________________________________________________________________________________________________\n",
    "\n",
    "class CausalConv1d(nn.Conv1d):\n",
    "    def __init__(self, in_ch, out_ch, k, dilation=1):\n",
    "        super().__init__(in_ch, out_ch, kernel_size=k, dilation=dilation, padding=0, bias=True)\n",
    "        self.left_pad = (k - 1) * dilation\n",
    "    def forward(self, x):\n",
    "        if self.left_pad > 0:\n",
    "            x = F.pad(x, (self.left_pad, 0))\n",
    "        return super().forward(x)\n",
    "\n",
    "class LayerNormChannel(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(C)\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2).contiguous()\n",
    "        x = self.ln(x)\n",
    "        return x.transpose(1, 2).contiguous()\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, C, k, dilation, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.conv1 = CausalConv1d(C, C, k, dilation)\n",
    "        self.act1  = nn.GELU()\n",
    "        self.norm1 = LayerNormChannel(C)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.conv2 = CausalConv1d(C, C, k, dilation)\n",
    "        self.act2  = nn.GELU()\n",
    "        self.norm2 = LayerNormChannel(C)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.drop1(self.norm1(self.act1(self.conv1(x))))\n",
    "        x = self.drop2(self.norm2(self.act2(self.conv2(x))))\n",
    "        return x + residual\n",
    "\n",
    "class DilatedCausalCNN(nn.Module):\n",
    "    def __init__(self, in_feats, C=64, k=5, dilations=(1,2,4,8,16,32), horizon=24, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.in_proj = nn.Conv1d(in_feats, C, kernel_size=1)\n",
    "        self.blocks = nn.ModuleList([ResBlock(C, k=k, dilation=d, dropout=dropout) for d in dilations])\n",
    "        self.head_norm = LayerNormChannel(C)\n",
    "        self.head = nn.Linear(C, horizon)\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, F] -> [B, F, L]\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.in_proj(x)\n",
    "        for b in self.blocks:\n",
    "            x = b(x)\n",
    "        last_step = self.head_norm(x)[:, :, -1]  # [B, C]\n",
    "        yhat = self.head(last_step)              # [B, H]\n",
    "        return yhat\n",
    "\n",
    "#___________________________________________________________________________________________________\n",
    "##\n",
    "## Metrics, Baselines & MASKED LOSS / METRICS\n",
    "##___________________________________________________________________________________________________\n",
    "\n",
    "def masked_huber_loss(yhat, y, mask, delta=1.0):\n",
    "    \"\"\"\n",
    "    Computes Huber loss on valid (unmasked) elements.\n",
    "    mask: 1 for valid, 0 for invalid. Shapes [B, H].\n",
    "    \"\"\"\n",
    "    loss_per_element = F.huber_loss(yhat, y, reduction='none', delta=delta)\n",
    "    masked_loss = loss_per_element * mask\n",
    "    mean_loss = masked_loss.sum() / (mask.sum() + 1e-9)\n",
    "    return mean_loss\n",
    "\n",
    "def masked_rmse(yhat, y, mask, eps=1e-9):\n",
    "    err = (yhat - y) ** 2 * mask\n",
    "    return torch.sqrt(err.sum() / (mask.sum() + eps))\n",
    "\n",
    "def per_horizon_masked_rmse(yhat, y, mask, eps=1e-9):\n",
    "    # yhat,y,mask: [N, H]\n",
    "    err = (yhat - y) ** 2 * mask\n",
    "    per_h = torch.sqrt(err.sum(dim=0) / (mask.sum(dim=0) + eps))\n",
    "    overall = torch.sqrt(err.sum() / (mask.sum() + eps))\n",
    "    return per_h, overall\n",
    "\n",
    "def receptive_field(k: int, dilations) -> int:\n",
    "    \"\"\"\n",
    "    Two causal convs per ResBlock; each adds (k-1)*d to RF.\n",
    "    RF = 1 + 2*(k-1)*sum(dilations)\n",
    "    \"\"\"\n",
    "    return 1 + 2 * (k - 1) * sum(dilations)\n",
    "\n",
    "# Persistence baseline helpers\n",
    "def last_valid_target(xb, x_mask_b, target_idx):\n",
    "    \"\"\"\n",
    "    xb: [B, L, F] (zero-imputed), x_mask_b: [B, L] (1 valid, 0 invalid if ANY feat NaN)\n",
    "    target_idx: index of target feature inside X\n",
    "    Returns: [B] last valid target value; falls back to last step if mask is all zeros.\n",
    "    \"\"\"\n",
    "    B, L, _ = xb.shape\n",
    "    rev = torch.flip(x_mask_b, dims=[1])           # [B, L]\n",
    "    last_valid_from_end = torch.argmax(rev, dim=1) # [B]\n",
    "    last_valid = (L - 1) - last_valid_from_end     # [B]\n",
    "    rows = torch.arange(B, device=xb.device)\n",
    "    return xb[rows, last_valid, target_idx]        # [B]\n",
    "\n",
    "#___________________________________________________________________________________________________\n",
    "##\n",
    "## Training Loop (MASKED VAL METRIC)\n",
    "##___________________________________________________________________________________________________\n",
    "\n",
    "def make_optimizer(model, lr=3e-4, weight_decay=1e-2):\n",
    "    # Exclude biases and norms from weight decay\n",
    "    decay, no_decay = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        if not p.requires_grad:\n",
    "            continue\n",
    "        if n.endswith(\"bias\") or (\"ln\" in n) or (\"norm\" in n):\n",
    "            no_decay.append(p)\n",
    "        else:\n",
    "            decay.append(p)\n",
    "    return torch.optim.AdamW(\n",
    "        [\n",
    "            {\"params\": decay, \"weight_decay\": weight_decay},\n",
    "            {\"params\": no_decay, \"weight_decay\": 0.0},\n",
    "        ],\n",
    "        lr=lr, betas=(0.9, 0.999)\n",
    "    )\n",
    "\n",
    "def train_loop(model, loaders, device, epochs=80, max_lr=3e-3, clip=1.0, patience=8):\n",
    "    train_loader, val_loader = loaders\n",
    "    opt = make_optimizer(model, lr=max_lr, weight_decay=1e-2)\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt, max_lr=max_lr, epochs=epochs, steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.1, div_factor=25.0, final_div_factor=1e4\n",
    "    )\n",
    "    best_val = float('inf')\n",
    "    best_state = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        t0 = time.time()\n",
    "        for xb, yb, x_mask_b, y_mask_b in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            y_mask_b = y_mask_b.to(device)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            yhat = model(xb)\n",
    "            loss = masked_huber_loss(yhat, yb, y_mask_b)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
    "            opt.step()\n",
    "            sched.step()\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # ---- Validation: MASKED RMSE for honest tracking ----\n",
    "        model.eval()\n",
    "        val_sum = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _, y_mask_b in val_loader:\n",
    "                xb, yb, y_mask_b = xb.to(device), yb.to(device), y_mask_b.to(device)\n",
    "                yhat = model(xb)\n",
    "                val_sum += masked_rmse(yhat, yb, y_mask_b).item() * xb.size(0)\n",
    "        val_rmse = val_sum / len(val_loader.dataset)\n",
    "\n",
    "        dt = time.time() - t0\n",
    "        print(f\"Epoch {ep:03d}/{epochs} | train_loss={train_loss:.5f} | val_RMSE(masked)={val_rmse:.5f} | dt={dt:.1f}s\")\n",
    "\n",
    "        if val_rmse < best_val:\n",
    "            best_val = val_rmse\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {ep} (no improvement for {patience} epochs)\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return best_val\n",
    "\n",
    "#___________________________________________________________________________________________________\n",
    "##\n",
    "## Main Execution Block\n",
    "##___________________________________________________________________________________________________\n",
    "\n",
    "def main():\n",
    "    # === Configuration ===\n",
    "    CFG = {\n",
    "        \"npz\": \"data/processed/sav_0927_v3.npz\",\n",
    "        \"horizon\": 24,\n",
    "        \"lookback\": 168,\n",
    "        \"batch_size\": 128,\n",
    "        \"epochs\": 80,\n",
    "        \"lr\": 3e-4,  # OneCycle max_lr\n",
    "        \"channels\": 64,\n",
    "        \"kernel\": 5,\n",
    "        \"dropout\": 0.1,\n",
    "        \"dilations\": \"1,2,4,8,16,32\",\n",
    "        \"seed\": 42,\n",
    "        \"save\": \"best_model.pt\",\n",
    "        \"num_workers\": 0,        # 0 for troubleshooting; autotune may bump this\n",
    "        \"target_feat_idx\": -1,   # index of target feature inside X (if applicable)\n",
    "        \"use_torch_compile\": True\n",
    "    }\n",
    "    print(\"Configuration:\")\n",
    "    print(json.dumps(CFG, indent=2))\n",
    "\n",
    "    set_seed(CFG[\"seed\"])\n",
    "    device = pick_device()\n",
    "    CFG = autotune_hparams(CFG, device)\n",
    "    print(f\"\\nUsing device: {device}\")\n",
    "    print(\"Autotuned Configuration:\")\n",
    "    print(json.dumps(CFG, indent=2))\n",
    "\n",
    "    # === Load & Prepare Data ===\n",
    "    Xtr, ytr, Xva, yva, Xte, yte = load_npz(CFG[\"npz\"])\n",
    "\n",
    "    # Trim to desired lookback/horizon if necessary\n",
    "    L, H = CFG[\"lookback\"], CFG[\"horizon\"]\n",
    "    if Xtr.shape[1] > L: Xtr, Xva, Xte = Xtr[:, -L:], Xva[:, -L:], Xte[:, -L:]\n",
    "    if ytr.shape[1] > H: ytr, yva, yte = ytr[:, :H], yva[:, :H], yte[:, :H]\n",
    "\n",
    "    # Z-score normalization (NaN-aware) using TRAIN stats\n",
    "    mu, sd = zscore_fit(Xtr)\n",
    "    Xtr = zscore_apply(Xtr, mu, sd)\n",
    "    Xva = zscore_apply(Xva, mu, sd)\n",
    "    Xte = zscore_apply(Xte, mu, sd)\n",
    "\n",
    "    # Create Datasets (masking inside)\n",
    "    train_ds = TSWindowDataset(Xtr, ytr)\n",
    "    val_ds   = TSWindowDataset(Xva, yva)\n",
    "    test_ds  = TSWindowDataset(Xte, yte)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=CFG[\"batch_size\"], shuffle=True,  num_workers=CFG[\"num_workers\"])\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=CFG[\"num_workers\"])\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=CFG[\"num_workers\"])\n",
    "\n",
    "    F = Xtr.shape[-1]\n",
    "    print(f\"Dataset sizes — train: {len(train_ds)}, val: {len(val_ds)}, test: {len(test_ds)}\")\n",
    "    print(f\"Features (F): {F}, Lookback (L): {L}, Horizon (H): {H}\\n\")\n",
    "\n",
    "    # === Initialize Model ===\n",
    "    dilations = tuple(int(x) for x in CFG[\"dilations\"].split(\",\"))\n",
    "    RF = receptive_field(CFG[\"kernel\"], dilations)\n",
    "    if L < RF:\n",
    "        print(f\"⚠️  Lookback ({L}) < receptive field ({RF}). Consider increasing lookback or reducing k/dilations.\")\n",
    "\n",
    "    model = DilatedCausalCNN(\n",
    "        in_feats=F, C=CFG[\"channels\"], k=CFG[\"kernel\"],\n",
    "        dilations=dilations, horizon=H, dropout=CFG[\"dropout\"]\n",
    "    ).to(device)\n",
    "\n",
    "    # Optional torch.compile for PyTorch 2.x\n",
    "    if CFG.get(\"use_torch_compile\", True):\n",
    "        try:\n",
    "            model = torch.compile(model)  # may no-op on older versions/backends\n",
    "            print(\"torch.compile enabled.\")\n",
    "        except Exception as e:\n",
    "            print(f\"torch.compile not available/failed: {e}\")\n",
    "\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Model params: {n_params:,}\\n\")\n",
    "\n",
    "    # === Train Model ===\n",
    "    print(\"Starting training...\")\n",
    "    best_val_rmse = train_loop(\n",
    "        model, (train_loader, val_loader), device,\n",
    "        epochs=CFG[\"epochs\"], max_lr=CFG[\"lr\"], clip=1.0, patience=8\n",
    "    )\n",
    "    print(f\"\\nTraining finished. Best validation RMSE (masked): {best_val_rmse:.6f}\")\n",
    "\n",
    "    # === Save Model & Normalization Stats ===\n",
    "    save_path = CFG[\"save\"]\n",
    "    save_dir = os.path.dirname(save_path)\n",
    "    if save_dir:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    torch.save({\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"mu\": mu, \"sd\": sd,\n",
    "        \"config\": CFG\n",
    "    }, save_path)\n",
    "    print(f\"Saved best model and stats to: {save_path}\")\n",
    "\n",
    "    # === Evaluate on Test Set (MASKED metrics + robust persistence) ===\n",
    "    TARGET_FEAT_IDX = CFG[\"target_feat_idx\"]\n",
    "    model.eval()\n",
    "    yhats, ys, lasts, y_masks = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, x_mask_b, y_mask_b in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            x_mask_b, y_mask_b = x_mask_b.to(device), y_mask_b.to(device)\n",
    "\n",
    "            yhat = model(xb)\n",
    "            yhats.append(yhat.cpu())\n",
    "            ys.append(yb.cpu())\n",
    "            y_masks.append(y_mask_b.cpu())\n",
    "            lasts.append(last_valid_target(xb, x_mask_b, TARGET_FEAT_IDX).detach().cpu())\n",
    "\n",
    "    yhat  = torch.cat(yhats,  dim=0)  # [N, H]\n",
    "    y     = torch.cat(ys,     dim=0)  # [N, H]\n",
    "    mask  = torch.cat(y_masks,dim=0)  # [N, H]\n",
    "    last  = torch.cat(lasts,  dim=0)  # [N]\n",
    "\n",
    "    base = last.unsqueeze(1).repeat(1, y.shape[1])  # [N, H]\n",
    "    ph_m, overall_m = per_horizon_masked_rmse(yhat, y, mask)\n",
    "    ph_b, overall_b = per_horizon_masked_rmse(base,  y, mask)\n",
    "    ph_skill = 1.0 - (ph_m / (ph_b + 1e-12))\n",
    "    overall_skill = 1.0 - (overall_m / (overall_b + 1e-12))\n",
    "\n",
    "    print(\"\\n=== Test Metrics (MASKED) ===\")\n",
    "    print(f\"Overall RMSE (model):       {overall_m.item():.4f}\")\n",
    "    print(f\"Overall RMSE (persistence): {overall_b.item():.4f}\")\n",
    "    print(f\"Overall Skill vs persist:   {overall_skill.item():.4f}\")\n",
    "    print(\"\\nPer-horizon (t+1..t+H):\")\n",
    "    for h in range(H):\n",
    "        print(f\"h+{h+1:02d}: RMSE_model={ph_m[h].item():.4f}  |  RMSE_persist={ph_b[h].item():.4f}  |  Skill={ph_skill[h].item():.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d436a8-06d7-4f5a-9597-0a42a044f9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
